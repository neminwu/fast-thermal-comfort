{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, box, mapping\n",
    "from shapely.ops import unary_union\n",
    "from scipy.ndimage import label\n",
    "from rasterstats import zonal_stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────────────────────────────\n",
    "RASTER_PATH = \"nDSM_veg_cleaned_6491.tif\"\n",
    "INT_DIR     = \"/storage/scratch1/4/hyu483/no_heat/test_10k\"\n",
    "OUTPUT_PATH = \"/storage/scratch1/4/hyu483/no_heat/merged_vegetation.geojson\"\n",
    "PRJ_CRS = 6491\n",
    "TILE_SIZE   = 5000      # pixels\n",
    "BUFFER_PX   = 100       # pixels\n",
    "CONNECTIVITY_STRUCT = np.array([[0,1,0],\n",
    "                                [1,1,1],\n",
    "                                [0,1,0]], dtype=int)\n",
    "BUFFER_DIST = 2.0       # meters\n",
    "MIN_AREA    = 2.0       # m²\n",
    "TOL = 0.5               # tolerance of geometry simplification \n",
    "# ────────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a80f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tile(args):\n",
    "    \"\"\"Read one window, vectorize, buffer/merge/dedeuffer, zonal‐stats, crop, write.\"\"\"\n",
    "    row_off, col_off, win_h, win_w = args\n",
    "    out_fp = os.path.join(INT_DIR, f\"chunk_r{row_off}_c{col_off}.geojson\")\n",
    "#     if os.path.exists(out_fp):\n",
    "#         return  # skip existing\n",
    "\n",
    "    with rasterio.open(RASTER_PATH) as src:\n",
    "        # build buffered window, clipped to raster bounds\n",
    "        buf = BUFFER_PX\n",
    "        row0 = max(0, row_off - buf)\n",
    "        col0 = max(0, col_off - buf)\n",
    "        row1 = min(src.height, row_off + win_h + buf)\n",
    "        col1 = min(src.width,  col_off + win_w + buf)\n",
    "\n",
    "        window = Window(col0, row0, col1 - col0, row1 - row0)\n",
    "        data = src.read(1, window=window)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = 0\n",
    "\n",
    "        if data.sum() == 0:\n",
    "            return  # nothing here\n",
    "\n",
    "        # connected‐component labeling\n",
    "        mask = data != 0\n",
    "        labeled, nlabels = label(mask, structure=CONNECTIVITY_STRUCT)\n",
    "\n",
    "        # vectorize all regions at once\n",
    "        geoms = []\n",
    "        transform = src.window_transform(window)\n",
    "        for geom, val in shapes(labeled, mask=(labeled > 0), transform=transform):\n",
    "            # only keep the “shape” geometry, ignore val\n",
    "            shp = shape(geom)\n",
    "            # buffer→merge step will be done below\n",
    "            geoms.append(shp)\n",
    "\n",
    "        if not geoms:\n",
    "            return\n",
    "\n",
    "        # merge all, buffer out then back in, filter by area\n",
    "        merged = unary_union(geoms).buffer(BUFFER_DIST)\n",
    "        cleaned = merged.buffer(-BUFFER_DIST)\n",
    "        if cleaned.is_empty:\n",
    "            return\n",
    "\n",
    "        # explode multi‐geoms and filter small bits\n",
    "        polys = []\n",
    "        for poly in (cleaned.geoms if hasattr(cleaned, 'geoms') else [cleaned]):\n",
    "            if poly.area >= MIN_AREA:\n",
    "                polys.append(poly)\n",
    "\n",
    "        if not polys:\n",
    "            return\n",
    "\n",
    "        # compute zonal stats (mean) on original raster\n",
    "        zs = zonal_stats(\n",
    "            polys,\n",
    "            RASTER_PATH,\n",
    "            stats=['mean'],\n",
    "            all_touched=True,\n",
    "            geojson_out=False\n",
    "        )\n",
    "\n",
    "        # build GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            [{'mean_h': z['mean']} for z in zs],\n",
    "            geometry=polys,\n",
    "            crs=PRJ_CRS\n",
    "        )\n",
    "\n",
    "        # crop back to the un‐buffered tile extent\n",
    "        # tile bounds in map coords:\n",
    "        top_left = src.transform * (col_off, row_off)\n",
    "        bottom_right = src.transform * (col_off + win_w, row_off + win_h)\n",
    "        tile_box = box(\n",
    "            top_left[0], bottom_right[1],\n",
    "            bottom_right[0], top_left[1]\n",
    "        )\n",
    "        gdf['geometry'] = gdf.geometry.intersection(tile_box)\n",
    "        gdf = gdf[~gdf.geometry.is_empty]\n",
    "\n",
    "        # write out\n",
    "        if not os.path.exists(INT_DIR):\n",
    "            os.makedirs(INT_DIR)\n",
    "        gdf.to_file(out_fp, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # prepare tile windows\n",
    "    with rasterio.open(RASTER_PATH) as src:\n",
    "        nrows = math.ceil(src.height / TILE_SIZE)\n",
    "        ncols = math.ceil(src.width  / TILE_SIZE)\n",
    "\n",
    "    tasks = []\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            row_off = i * TILE_SIZE\n",
    "            col_off = j * TILE_SIZE\n",
    "            win_h = min(TILE_SIZE, src.height - row_off)\n",
    "            win_w = min(TILE_SIZE, src.width  - col_off)\n",
    "            tasks.append((row_off, col_off, win_h, win_w))\n",
    "\n",
    "    # parallel processing\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        pool.map(process_tile, tasks)\n",
    "\n",
    "    # merge all chunks\n",
    "    all_files = glob.glob(os.path.join(INT_DIR, \"chunk_*.geojson\"))\n",
    "    gdfs = [gpd.read_file(fp) for fp in all_files]\n",
    "    if gdfs:\n",
    "        print(gdfs[0].crs)\n",
    "        merged = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), geometry = 'geometry', crs=gdfs[0].crs)\n",
    "        #    Each node is a feature index; edges link features that intersect.\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(merged.index)\n",
    "        \n",
    "        # use spatial index for speed\n",
    "        sindex = merged.sindex\n",
    "        for idx, geom in merged.geometry.items():\n",
    "            # find candidates whose bbox touches this one\n",
    "            possible = list(sindex.intersection(geom.bounds))\n",
    "            for j in possible:\n",
    "                if idx < j and geom.intersects(merged.geometry[j]):\n",
    "                    G.add_edge(idx, j)    \n",
    "\n",
    "        # ── 3) Extract connected components ──────────────────────────────────────────\n",
    "        #    Each component is a set of indices to dissolve together.\n",
    "        components = list(nx.connected_components(G))\n",
    "        # map each original index → its component ID\n",
    "        comp_map = {}\n",
    "        for comp_id, comp in enumerate(components):\n",
    "            for idx in comp:\n",
    "                comp_map[idx] = comp_id\n",
    "        \n",
    "        merged[\"grp\"] = merged.index.map(comp_map)\n",
    "\n",
    "        # ── 4) Dissolve by component, averaging mean_h ─────────────────────────────\n",
    "        dissolved = merged.dissolve(\n",
    "            by=\"grp\",\n",
    "            aggfunc={ \"mean_h\": \"mean\" }  # aggregates mean_h across the group\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        final = dissolved[[\"mean_h\", \"geometry\"]]\n",
    "        final['mean_h'] = final['mean_h'].round().astype(int)\n",
    "\n",
    "        # ── 5) Simplification ───────────────────────────────────────────────────────\n",
    "        final_simple = final.copy()\n",
    "        final_simple[\"geometry\"] = final_simple.geometry.simplify(tolerance=TOL, preserve_topology=True)\n",
    "\n",
    "        final_simple.to_file(OUTPUT_PATH, driver=\"GeoJSON\")\n",
    "        print(\"Saved final dissolved vegetation.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    main()\n",
    "    print(f\"processing time: {time.time() - start} s\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
