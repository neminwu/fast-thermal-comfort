{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed213d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "from qgis.core import QgsApplication\n",
    "app = QgsApplication([], False)\n",
    "app.setPrefixPath(\"/apps/anvil/external/apps/qgis/3.40.1-Bratislava\", True)\n",
    "# Use the actual plugin path\n",
    "plugin_path = os.path.expanduser(\"~/.local/share/QGIS/QGIS3/profiles/default/python/plugins\")\n",
    "app.setPluginPath(plugin_path)\n",
    "app.initQgis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fe266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if plugin_path not in sys.path:\n",
    "\tsys.path.append(plugin_path)\n",
    "\n",
    "import processing\n",
    "from processing.core.Processing import Processing\n",
    "\n",
    "try:\n",
    "    from processing_umep.processing_umep_provider import ProcessingUMEPProvider\n",
    "    umep_provider = ProcessingUMEPProvider()\n",
    "    QgsApplication.processingRegistry().addProvider(umep_provider)\n",
    "    print(\"UMEP imported\")\n",
    "except Exception as e:\n",
    "\tprint(\"UMEP import error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from osgeo import gdal, osr # osr is needed for SpatialReference\n",
    "import zipfile\n",
    "import time\n",
    "import traceback\n",
    "from qgis import processing # Assuming QGIS environment is correctly set up\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import shutil\n",
    "\n",
    "# === CONFIGURATION (Identical to your previous script) ===\n",
    "tile_size = 500\n",
    "buffer_pixels = 100\n",
    "\n",
    "# Temporary directories\n",
    "base_source_data_dir = \"/storage/scratch1/4/hyu483/no_heat/SOLWEIG/Input/Final_Rasters\"\n",
    "temp_base_dir = \"/storage/scratch1/4/hyu483/no_heat/SOLWEIG/Temp/Final_Run_2\"\n",
    "base_tile_buffered_input_dir = os.path.join(temp_base_dir, \"Buffered_Inputs\")\n",
    "base_solweig_buffered_output_dir = os.path.join(temp_base_dir, \"Buffered_SOLWEIG_Output\")\n",
    "\n",
    "# Output directories\n",
    "final_output_base_dir = \"/storage/scratch1/4/hyu483/no_heat/SOLWEIG/Output/Final_Run_2\"\n",
    "base_tile_debuffered_output_dir = os.path.join(final_output_base_dir, \"Debuffered_Tiles\")\n",
    "merged_output_dir = os.path.join(final_output_base_dir, \"Merged_Output\")\n",
    "\n",
    "PATHS_CONFIG = {\n",
    "    \"bDSM\": os.path.join(base_source_data_dir, \"DSM_aligned.tif\"),\n",
    "    \"cDSM\": os.path.join(base_source_data_dir, \"cDSM_aligned.tif\"),\n",
    "    \"dem\": os.path.join(base_source_data_dir, \"DEM_aligned.tif\"),\n",
    "    \"wall_aspect\": os.path.join(base_source_data_dir, \"wall_aspect_merged_aligned.tif\"),\n",
    "    \"wall_height\": os.path.join(base_source_data_dir, \"wall_height_merged_aligned.tif\"),\n",
    "    \"lc\": os.path.join(base_source_data_dir, \"LULC_6491_5class_aligned.tif\"),\n",
    "    \"svf_input_dir\": os.path.join(base_source_data_dir, \"SVF\"),\n",
    "    \"meteo\": '/storage/scratch1/4/hyu483/no_heat/SOLWEIG/Input/meteo_hot_typical.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20597ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.UseExceptions() # Enable GDAL exceptions\n",
    "\n",
    "# === HELPER FUNCTION ===\n",
    "def calculate_gdal_sub_geotransform(parent_gt, x_offset_pixels, y_offset_pixels):\n",
    "    \"\"\"\n",
    "    Calculates the GeoTransform for a sub-window of a raster based on pixel offsets.\n",
    "    \"\"\"\n",
    "    # parent_gt = [ulx, x_res, x_skew, uly, y_skew, y_res]\n",
    "    new_ulx = parent_gt[0] + x_offset_pixels * parent_gt[1] + y_offset_pixels * parent_gt[2]\n",
    "    new_uly = parent_gt[3] + x_offset_pixels * parent_gt[4] + y_offset_pixels * parent_gt[5]\n",
    "    return (new_ulx, parent_gt[1], parent_gt[2], new_uly, parent_gt[4], parent_gt[5])\n",
    "\n",
    "# === FUNCTION TO SLICE RASTER BY WINDOW AND SAVE (GDAL) ===\n",
    "def gdal_slice_raster_by_window(\n",
    "    raster_path: str,\n",
    "    out_path: str,\n",
    "    slice_c_off: int,\n",
    "    slice_r_off: int,\n",
    "    slice_win_width: int,\n",
    "    slice_win_height: int,\n",
    "    output_format: str = \"GTiff\",\n",
    "    # srcSRS: str = \"EPSG:26986\", ###\n",
    "    # dst_srs: str = \"EPSG:26986\", ###\n",
    "    resample_alg: str = \"bilinear\", ###\n",
    "    creation_options: list = None\n",
    "    ):\n",
    "    if creation_options is None:\n",
    "        creation_options = [\"TILED=YES\", \"COMPRESS=LZW\"]\n",
    "\n",
    "    # Open source and grab its geotransform\n",
    "    src_ds = gdal.Open(raster_path)\n",
    "    if not src_ds:\n",
    "        raise RuntimeError(f\"Could not open {raster_path}\")\n",
    "\n",
    "    gt = src_ds.GetGeoTransform()\n",
    "    origin_x, px_w, _, origin_y, _, px_h = gt\n",
    "\n",
    "    # Compute the geographic bounds of the pixel window\n",
    "    minx = origin_x + slice_c_off * px_w\n",
    "    maxx = minx + slice_win_width * px_w\n",
    "\n",
    "    # Note: px_h is typically negative, so maxy = origin_y + slice_r_off*px_h\n",
    "    maxy = origin_y + slice_r_off * px_h\n",
    "    miny = maxy + slice_win_height * px_h\n",
    "\n",
    "    # Make sure your output directory exists\n",
    "    out_dir = os.path.dirname(out_path)\n",
    "    if out_dir and not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Build the WarpOptions\n",
    "    warp_opts = gdal.WarpOptions(\n",
    "        format=output_format,\n",
    "        # dstSRS=dst_srs,\n",
    "        resampleAlg=resample_alg,\n",
    "        creationOptions=creation_options,\n",
    "        outputBounds=[minx, miny, maxx, maxy],\n",
    "        width=slice_win_width,\n",
    "        height=slice_win_height\n",
    "    )\n",
    "\n",
    "    # Do the warp (crop)\n",
    "    ds = gdal.Warp(\n",
    "        destNameOrDestDS=out_path,\n",
    "        srcDSOrSrcDSTab=raster_path,\n",
    "        options=warp_opts\n",
    "    )\n",
    "    if ds is None:\n",
    "        raise RuntimeError(\"gdal.Warp failed\")\n",
    "\n",
    "    # Close datasets\n",
    "    ds = None\n",
    "    src_ds = None\n",
    "\n",
    "    return out_path\n",
    "\n",
    "# === FUNCTION TO DEBUFFER AND SAVE RASTER (GDAL) ===\n",
    "def debuffer_and_save_raster_gdal(\n",
    "    buffered_raster_path: str,\n",
    "    debuffered_raster_path: str,\n",
    "    original_full_raster_geotransform: tuple, # GeoTransform of the *original* large source raster\n",
    "    original_core_tile_col_off_in_full: int, # Column offset of the core tile within the full raster\n",
    "    original_core_tile_row_off_in_full: int, # Row offset of the core tile within the full raster\n",
    "    core_tile_width: int,                   # Width of the non-buffered core data\n",
    "    core_tile_height: int,                  # Height of the non-buffered core data\n",
    "    actual_buffer_on_left_pixels: int,      # Buffer pixels on the left *within the buffered_raster_path*\n",
    "    actual_buffer_on_top_pixels: int        # Buffer pixels on the top *within the buffered_raster_path*\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Clips the core data from a buffered raster using GDAL and saves it\n",
    "    with correct global georeferencing.\n",
    "    \"\"\"\n",
    "    src_buffered_ds = gdal.Open(buffered_raster_path, gdal.GA_ReadOnly)\n",
    "    if src_buffered_ds is None:\n",
    "        print(f\"ERROR: Could not open buffered raster: {buffered_raster_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        src_buffered_band = src_buffered_ds.GetRasterBand(1)\n",
    "        if src_buffered_band is None:\n",
    "            print(f\"ERROR: Could not get band from {buffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "        # Read the core data from the buffered raster\n",
    "        # xoff, yoff, xsize, ysize for ReadAsArray\n",
    "        core_data = src_buffered_band.ReadAsArray(\n",
    "            xoff=actual_buffer_on_left_pixels,\n",
    "            yoff=actual_buffer_on_top_pixels,\n",
    "            win_xsize=core_tile_width,\n",
    "            win_ysize=core_tile_height\n",
    "        ).astype(float)\n",
    "\n",
    "        if core_data is None:\n",
    "            print(f\"ERROR: Failed to read core data from {buffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "        \n",
    "        if core_data.shape[0] != core_tile_height or core_data.shape[1] != core_tile_width:\n",
    "            print(f\"ERROR: Read core data shape ({core_data.shape}) does not match expected ({core_tile_height}, {core_tile_width}) for {debuffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "\n",
    "        # Calculate the correct geotransform for this debuffered (core) tile.\n",
    "        # This transform places the core tile in its correct global position.\n",
    "        final_core_geotransform = calculate_gdal_sub_geotransform(\n",
    "            original_full_raster_geotransform,\n",
    "            original_core_tile_col_off_in_full,\n",
    "            original_core_tile_row_off_in_full\n",
    "        )\n",
    "\n",
    "        # Create the output debuffered raster\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        if driver is None:\n",
    "            print(\"ERROR: GTiff driver not available.\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "            \n",
    "        os.makedirs(os.path.dirname(debuffered_raster_path), exist_ok=True)\n",
    "        \n",
    "        # Get data type from source buffered band\n",
    "        gdal_data_type = src_buffered_band.DataType\n",
    "        \n",
    "        dst_ds = driver.Create(\n",
    "            debuffered_raster_path,\n",
    "            xsize=core_tile_width,\n",
    "            ysize=core_tile_height,\n",
    "            bands=1, # Assuming single band TMRT\n",
    "            eType=gdal_data_type,\n",
    "            options=[\"COMPRESS=LZW\"] # Add other options if needed\n",
    "        )\n",
    "        if dst_ds is None:\n",
    "            print(f\"ERROR: Could not create output raster: {debuffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "        dst_ds.SetGeoTransform(final_core_geotransform)\n",
    "        dst_ds.SetProjection(src_buffered_ds.GetProjection()) # Preserve CRS\n",
    "\n",
    "        dst_band = dst_ds.GetRasterBand(1)\n",
    "        dst_band.WriteArray(core_data)\n",
    "        no_data_value = src_buffered_band.GetNoDataValue()\n",
    "        if no_data_value is not None:\n",
    "            dst_band.SetNoDataValue(no_data_value)\n",
    "        \n",
    "        dst_band.FlushCache()\n",
    "        dst_ds = None # Close and save\n",
    "\n",
    "        return debuffered_raster_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during debuffering for {buffered_raster_path} to {debuffered_raster_path}: {e}\\n{traceback.format_exc()}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if src_buffered_ds:\n",
    "            src_buffered_ds = None\n",
    "\n",
    "\n",
    "# === WORKER FUNCTION FOR PROCESSING A SINGLE TILE ===\n",
    "def process_tile_with_buffer(\n",
    "    core_r_offset, core_c_offset,\n",
    "    core_tile_width, core_tile_height,\n",
    "    buffer_px,\n",
    "    full_raster_total_width, full_raster_total_height,\n",
    "    original_full_raster_geotransform_tuple, original_full_raster_crs_wkt, # GDAL specific\n",
    "    paths_cfg_dict,\n",
    "    base_buffered_input_dir_worker,\n",
    "    base_solweig_out_dir_worker,\n",
    "    base_debuffered_out_dir_worker,\n",
    "    tile_id_str\n",
    "    ):\n",
    "    print(f\"[{tile_id_str}] Starting processing with buffer...\")\n",
    "    tile_processing_start_time = time.time()\n",
    "    debuffered_output_files_for_this_tile = []\n",
    "\n",
    "    try:\n",
    "        # --- 1. Calculate Buffered Window for Slicing Inputs ---\n",
    "        slice_r_off = max(0, core_r_offset - buffer_px)\n",
    "        slice_c_off = max(0, core_c_offset - buffer_px)\n",
    "        slice_r_end = min(full_raster_total_height, core_r_offset + core_tile_height + buffer_px)\n",
    "        slice_c_end = min(full_raster_total_width, core_c_offset + core_tile_width + buffer_px)\n",
    "        slice_win_height = (slice_r_end - slice_r_off)\n",
    "        slice_win_width = (slice_c_end - slice_c_off)\n",
    "\n",
    "        if slice_win_width <= 0 or slice_win_height <= 0:\n",
    "            msg = f\"[{tile_id_str}] Skipped: Calculated buffered slice window has zero/negative dimension. W:{slice_win_width} H:{slice_win_height}\"\n",
    "            print(msg)\n",
    "            return msg # Return error/skip message\n",
    "\n",
    "        actual_buffer_left = core_c_offset - slice_c_off\n",
    "        actual_buffer_top = core_r_offset - slice_r_off\n",
    "\n",
    "        # --- 2. Prepare Directories for this Tile ---\n",
    "        current_tile_buffered_data_dir = os.path.join(base_buffered_input_dir_worker, tile_id_str)\n",
    "        current_tile_solweig_output_dir = os.path.join(base_solweig_out_dir_worker, tile_id_str)\n",
    "        current_tile_buffered_svf_dir = os.path.join(current_tile_buffered_data_dir, \"svf_buffered_tiles\")\n",
    "        os.makedirs(current_tile_solweig_output_dir, exist_ok=True)\n",
    "        current_tile_debuffered_output_dir = os.path.join(base_debuffered_out_dir_worker, tile_id_str)\n",
    "        os.makedirs(current_tile_debuffered_output_dir, exist_ok=True)\n",
    "\n",
    "         # *** EDITED SECTION 1: CHECK FOR EXISTING OUTPUT ***\n",
    "        required_tmrt_filenames = [\n",
    "            \"Tmrt_2023_208_0900D.tif\", \"Tmrt_2023_208_1300D.tif\", \"Tmrt_2023_208_1700D.tif\",\n",
    "            \"Tmrt_2023_236_0900D.tif\", \"Tmrt_2023_236_1300D.tif\", \"Tmrt_2023_236_1700D.tif\",\n",
    "        ]\n",
    "        all_files_exist = all(os.path.exists(os.path.join(current_tile_solweig_output_dir, f)) for f in required_tmrt_filenames)\n",
    "        if all_files_exist:\n",
    "            print(f\"[{tile_id_str}] Found all {len(required_tmrt_filenames)} required SOLWEIG output files. Skipping processing run.\")\n",
    "        else:\n",
    "            os.makedirs(current_tile_buffered_data_dir, exist_ok=True)\n",
    "            os.makedirs(current_tile_buffered_svf_dir, exist_ok=True)\n",
    "            # --- 3. Slice Main Input Rasters (Buffered) ---\n",
    "            tile_specific_buffered_inputs = {}\n",
    "            for key in [\"bDSM\", \"cDSM\", \"dem\", \"wall_aspect\", \"wall_height\", \"lc\"]:\n",
    "                in_path = paths_cfg_dict[key]\n",
    "                out_filename = f\"{key}_{tile_id_str}_buffered.tif\"\n",
    "                out_path = os.path.join(current_tile_buffered_data_dir, out_filename)\n",
    "                tile_specific_buffered_inputs[key] = gdal_slice_raster_by_window(\n",
    "                    raster_path=in_path, out_path=out_path,\n",
    "                    slice_c_off=slice_c_off, slice_r_off=slice_r_off,\n",
    "                    slice_win_width=slice_win_width, slice_win_height=slice_win_height\n",
    "                )\n",
    "                if tile_specific_buffered_inputs[key] is None: # Check if slicing failed\n",
    "                     raise RuntimeError(f\"Failed to slice {key} for {tile_id_str}\")\n",
    "    \n",
    "    \n",
    "            # --- 4. Clip and Zip SVF Files (Buffered) ---\n",
    "            source_svf_files = sorted(glob.glob(os.path.join(paths_cfg_dict['svf_input_dir'], \"*.tif\")))\n",
    "            clipped_svf_paths_for_zip = []\n",
    "            if source_svf_files:\n",
    "                for svf_file_path in source_svf_files:\n",
    "                    filename = os.path.basename(svf_file_path)\n",
    "                    out_svf_filename = f\"{os.path.splitext(filename)[0]}_{tile_id_str}_buffered{os.path.splitext(filename)[1]}\"\n",
    "                    out_svf_tile_path = os.path.join(current_tile_buffered_svf_dir, out_svf_filename)\n",
    "                    clipped_path = gdal_slice_raster_by_window(\n",
    "                        raster_path=svf_file_path, out_path=out_svf_tile_path,\n",
    "                        slice_c_off=slice_c_off, slice_r_off=slice_r_off,\n",
    "                        slice_win_width=slice_win_width, slice_win_height=slice_win_height\n",
    "                    )\n",
    "                    if clipped_path:\n",
    "                        clipped_svf_paths_for_zip.append(clipped_path)\n",
    "                    else:\n",
    "                        print(f\"[{tile_id_str}] WARNING: Failed to slice SVF file: {svf_file_path}\")\n",
    "    \n",
    "    \n",
    "            tile_svf_zip_path = None\n",
    "            if clipped_svf_paths_for_zip:\n",
    "                tile_svf_zip_path = os.path.join(current_tile_buffered_data_dir, f\"svfs_{tile_id_str}_buffered.zip\")\n",
    "                if os.path.exists(tile_svf_zip_path): os.remove(tile_svf_zip_path)\n",
    "                with zipfile.ZipFile(tile_svf_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                    for svf_tile_path in clipped_svf_paths_for_zip:\n",
    "                        original_basename = os.path.basename(svf_tile_path).split(f'_{tile_id_str}_buffered')[0] + os.path.splitext(svf_tile_path)[1]\n",
    "                        zipf.write(svf_tile_path, arcname=original_basename)\n",
    "            \n",
    "            elif source_svf_files:\n",
    "                print(f\"[{tile_id_str}] WARNING: SVF files found but no SVFs were successfully clipped/zipped for buffered tile.\")\n",
    "    \n",
    "            # --- 5. Run SOLWEIG on Buffered Inputs ---\n",
    "            solweig_params = {\n",
    "                'INPUT_DSM': tile_specific_buffered_inputs.get('bDSM'),\n",
    "                'INPUT_SVF': tile_svf_zip_path, # This can be None if SVFs failed\n",
    "                'INPUT_HEIGHT': tile_specific_buffered_inputs.get('wall_height'),\n",
    "                'INPUT_ASPECT': tile_specific_buffered_inputs.get('wall_aspect'),\n",
    "                'INPUT_CDSM': tile_specific_buffered_inputs.get('cDSM'),\n",
    "                'INPUT_LC': tile_specific_buffered_inputs.get('lc'),\n",
    "                'INPUT_DEM': tile_specific_buffered_inputs.get('dem'),\n",
    "                'INPUTMET': paths_cfg_dict['meteo'],\n",
    "                'OUTPUT_DIR': current_tile_solweig_output_dir,\n",
    "                'TRANS_VEG': 3, 'LEAF_START': 97, 'LEAF_END': 300, 'CONIFER_TREES': False,\n",
    "                'INPUT_TDSM': None, 'INPUT_THEIGHT': 25, 'USE_LC_BUILD': False,\n",
    "                'SAVE_BUILD': False, 'INPUT_ANISO': '', 'ALBEDO_WALLS': 0.2, 'ALBEDO_GROUND': 0.15,\n",
    "                'EMIS_WALLS': 0.9, 'EMIS_GROUND': 0.95, 'ABS_S': 0.7, 'ABS_L': 0.95,\n",
    "                'POSTURE': 0, 'CYL': True, 'ONLYGLOBAL': True, 'UTC': 0,\n",
    "                'POI_FILE': None, 'POI_FIELD': '', 'AGE': 35, 'ACTIVITY': 80, 'CLO': 0.9,\n",
    "                'WEIGHT': 75, 'HEIGHT': 180, 'SEX': 0, 'SENSOR_HEIGHT': 10,\n",
    "                'OUTPUT_TMRT': True, 'OUTPUT_KDOWN': False, 'OUTPUT_KUP': False, 'OUTPUT_LDOWN': False,\n",
    "                'OUTPUT_LUP': False, 'OUTPUT_SH': False, 'OUTPUT_TREEPLANTER': False,\n",
    "            }\n",
    "            critical_inputs_present = all([\n",
    "            solweig_params['INPUT_DSM'], solweig_params['INPUT_LC'], solweig_params['INPUT_DEM'],\n",
    "            # Make INPUT_SVF optional if your workflow allows it, otherwise keep it mandatory\n",
    "            solweig_params['INPUT_SVF'] if source_svf_files else True, # Only critical if source SVFs exist\n",
    "            solweig_params['INPUT_CDSM'], solweig_params['INPUT_HEIGHT'], solweig_params['INPUT_ASPECT']])\n",
    "        \n",
    "            if not critical_inputs_present:\n",
    "                missing_inputs = [k for k, v in solweig_params.items() if v is None and k.startswith('INPUT_')]\n",
    "                msg = f\"[{tile_id_str}] Skipped SOLWEIG: missing critical input files: {missing_inputs}.\"\n",
    "                print(msg)\n",
    "                # Still try to cleanup before returning\n",
    "                shutil.rmtree(current_tile_buffered_data_dir, ignore_errors=True)\n",
    "                return msg\n",
    "\n",
    "            print(f\"[{tile_id_str}] Running SOLWEIG. Output dir: {solweig_params['OUTPUT_DIR']}\")\n",
    "            processing.run(\"umep:Outdoor Thermal Comfort: SOLWEIG\", solweig_params)\n",
    "            proc_time = (time.time() - tile_processing_start_time) / 60\n",
    "            print(f\"[{tile_id_str}] SOLWEIG processing complete in {proc_time:.2f} mins.\")\n",
    "            \n",
    "        # *** EDITED SECTION 2: CLEANUP ***\n",
    "        print(f\"[{tile_id_str}] Cleaning up temporary buffered input directory: {current_tile_buffered_data_dir}\")\n",
    "        try:\n",
    "            shutil.rmtree(current_tile_buffered_data_dir, ignore_errors=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[{tile_id_str}] WARNING: Could not clean up temporary directory {current_tile_buffered_data_dir}: {e}\")\n",
    "\n",
    "        proc_time = (time.time() - tile_processing_start_time) / 60\n",
    "        print(f\"[{tile_id_str}] Tile task finished in {proc_time:.2f} mins.\")\n",
    "        \n",
    "        # --- 6. Debuffer the TMRT Output ---\n",
    "        tmrt_glob_pattern = os.path.join(current_tile_solweig_output_dir, \"Tmrt_*.tif\")\n",
    "        all_buffered_tmrt_files = glob.glob(tmrt_glob_pattern)\n",
    "\n",
    "        if not all_buffered_tmrt_files:\n",
    "            print(f\"[{tile_id_str}] WARNING: No TMRT output files found in {current_tile_solweig_output_dir} after SOLWEIG run.\")\n",
    "            # This might not be an error if SOLWEIG was not expected to produce TMRT in some cases\n",
    "            # but usually it's an indication of a problem with the SOLWEIG run itself.\n",
    "\n",
    "        for buffered_tmrt_path in all_buffered_tmrt_files:\n",
    "            buffered_tmrt_filename_base = os.path.basename(buffered_tmrt_path)\n",
    "            debuffered_tmrt_filename = f\"{os.path.splitext(buffered_tmrt_filename_base)[0]}_{tile_id_str}_debuffered.tif\"\n",
    "            debuffered_tmrt_path = os.path.join(current_tile_debuffered_output_dir, debuffered_tmrt_filename)\n",
    "\n",
    "            # Parameters for debuffer_and_save_raster_gdal:\n",
    "            debuffered_file = debuffer_and_save_raster_gdal(\n",
    "                buffered_raster_path=buffered_tmrt_path,\n",
    "                debuffered_raster_path=debuffered_tmrt_path,\n",
    "                original_full_raster_geotransform=original_full_raster_geotransform_tuple,\n",
    "                original_core_tile_col_off_in_full=core_c_offset,\n",
    "                original_core_tile_row_off_in_full=core_r_offset,\n",
    "                core_tile_width=core_tile_width,\n",
    "                core_tile_height=core_tile_height,\n",
    "                actual_buffer_on_left_pixels=actual_buffer_left,\n",
    "                actual_buffer_on_top_pixels=actual_buffer_top\n",
    "            )\n",
    "            if debuffered_file:\n",
    "                debuffered_output_files_for_this_tile.append(debuffered_file)\n",
    "                print(f\"[{tile_id_str}] Successfully debuffered: {debuffered_file}\")\n",
    "            else:\n",
    "                print(f\"[{tile_id_str}] ERROR failed to debuffer: {buffered_tmrt_path}\")\n",
    "\n",
    "\n",
    "        if not debuffered_output_files_for_this_tile and all_buffered_tmrt_files:\n",
    "            msg = f\"[{tile_id_str}] ERROR: Found TMRT files but failed to debuffer any.\"\n",
    "            print(msg)\n",
    "            return msg\n",
    "        \n",
    "        proc_time = (time.time() - tile_processing_start_time) / 60\n",
    "        msg = f\"[{tile_id_str}] Tile processing (buffered) complete in {proc_time:.2f} mins. {len(debuffered_output_files_for_this_tile)} TMRT files debuffered.\"\n",
    "        print(msg)\n",
    "        return debuffered_output_files_for_this_tile\n",
    "\n",
    "    except Exception as e:\n",
    "        err_msg = f\"[{tile_id_str}] ERROR processing tile: {e}\\n{traceback.format_exc()}\"\n",
    "        print(err_msg)\n",
    "        return err_msg\n",
    "\n",
    "\n",
    "# === MAIN SCRIPT EXECUTION ===\n",
    "def main():\n",
    "    overall_start_time = time.time()\n",
    "    os.makedirs(base_tile_buffered_input_dir, exist_ok=True)\n",
    "    os.makedirs(base_solweig_buffered_output_dir, exist_ok=True)\n",
    "    os.makedirs(base_tile_debuffered_output_dir, exist_ok=True)\n",
    "    os.makedirs(merged_output_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        meteo_data = np.genfromtxt(PATHS_CONFIG['meteo'], delimiter=None)\n",
    "        if meteo_data.ndim == 0 or meteo_data.size == 0:\n",
    "            raise ValueError(\"Meteorological data is empty.\")\n",
    "        print(f\"Meteorological data shape: {meteo_data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR reading meteorological file: {PATHS_CONFIG['meteo']}. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Get dimensions and georeferencing from one of the main full-sized rasters using GDAL ---\n",
    "    ref_ds = gdal.Open(PATHS_CONFIG['dem'], gdal.GA_ReadOnly)\n",
    "    if ref_ds is None:\n",
    "        print(f\"CRITICAL ERROR: Could not open reference raster: {PATHS_CONFIG['dem']}\")\n",
    "        return\n",
    "    full_raster_width = ref_ds.RasterXSize\n",
    "    full_raster_height = ref_ds.RasterYSize\n",
    "    original_raster_geotransform = ref_ds.GetGeoTransform() # Tuple\n",
    "    original_raster_crs_wkt = ref_ds.GetProjection()     # WKT string\n",
    "    ref_ds = None # Close it\n",
    "    print(f\"Full source raster dimensions: {full_raster_width}x{full_raster_height}, Tile Size: {tile_size}x{tile_size}, Buffer: {buffer_pixels}px\")\n",
    "    print(f\"Source GeoTransform: {original_raster_geotransform}\")\n",
    "    print(f\"Source CRS (WKT): {original_raster_crs_wkt[:100]}...\") # Print first 100 chars\n",
    "\n",
    "    tasks_for_pool = []\n",
    "\n",
    "    for r_idx, core_r_off in enumerate(range(0, full_raster_height, tile_size)):\n",
    "        for c_idx, core_c_off in enumerate(range(0, full_raster_height, tile_size)):\n",
    "            current_core_tile_width = min(tile_size, full_raster_width - core_c_off)\n",
    "            current_core_tile_height = min(tile_size, full_raster_height - core_r_off)\n",
    "\n",
    "            if current_core_tile_width <= 0 or current_core_tile_height <= 0:\n",
    "                print(f\"Skipping task generation for zero-dimension core tile at r_offset={core_r_off}, c_offset={core_c_off}\")\n",
    "                continue\n",
    "            \n",
    "            tile_identifier_string = f\"tile_{r_idx}_{c_idx}\"\n",
    "            task_args = (\n",
    "                core_r_off, core_c_off,\n",
    "                current_core_tile_width, current_core_tile_height,\n",
    "                buffer_pixels,\n",
    "                full_raster_width, full_raster_height,\n",
    "                original_raster_geotransform, original_raster_crs_wkt, # Pass GDAL specific info\n",
    "                PATHS_CONFIG,\n",
    "                base_tile_buffered_input_dir,\n",
    "                base_solweig_buffered_output_dir,\n",
    "                base_tile_debuffered_output_dir,\n",
    "                tile_identifier_string\n",
    "            )\n",
    "            tasks_for_pool.append(task_args)\n",
    "\n",
    "    if not tasks_for_pool:\n",
    "        print(\"No tasks generated.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nGenerated {len(tasks_for_pool)} tasks for multiprocessing.\")\n",
    "    num_processes = min(max(1, os.cpu_count() - 2), 40)\n",
    "    # num_processes = 1 # For testing\n",
    "    print(f\"Using {num_processes} processes.\")\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results_from_pool = pool.starmap(process_tile_with_buffer, tasks_for_pool)\n",
    "    \n",
    "    print(\"\\n=== Multiprocessing of tiles complete. ===\")\n",
    "\n",
    "    organized_debuffered_files = {}\n",
    "    failed_tile_processing_count = 0\n",
    "    for result_item in results_from_pool:\n",
    "        if isinstance(result_item, str) and (\"ERROR\" in result_item or \"Skipped\" in result_item or \"WARNING\" in result_item): # Check for string error messages\n",
    "            failed_tile_processing_count += 1\n",
    "            # Error/skip message already printed by worker\n",
    "        elif isinstance(result_item, list): # Successful result is a list of debuffered paths\n",
    "            for debuffered_path in result_item:\n",
    "                if os.path.exists(debuffered_path):\n",
    "                    filename = os.path.basename(debuffered_path)\n",
    "                    parts = filename.split('_tile_')[0]\n",
    "                    tmrt_type_key = parts\n",
    "                    if tmrt_type_key not in organized_debuffered_files:\n",
    "                        organized_debuffered_files[tmrt_type_key] = []\n",
    "                    organized_debuffered_files[tmrt_type_key].append(debuffered_path)\n",
    "                else:\n",
    "                    print(f\"Warning: Worker reported debuffered file, but not found: {debuffered_path}\")\n",
    "        else: # Unrecognized result type\n",
    "            failed_tile_processing_count +=1\n",
    "            print(f\"  Unknown result type from worker for a tile: {type(result_item)} - {str(result_item)[:200]}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nTile processing summary: {len(results_from_pool) - failed_tile_processing_count} tiles had successful outcomes (returned list of paths).\")\n",
    "    print(f\"Tiles that returned error/skip messages or unknown result types: {failed_tile_processing_count}\")\n",
    "\n",
    "\n",
    "    if not organized_debuffered_files:\n",
    "        print(\"No debuffered files were successfully organized for merging.\")\n",
    "        overall_proc_time_early_exit = (time.time() - overall_start_time) / 60\n",
    "        print(f\"\\nTotal script execution time: {overall_proc_time_early_exit:.2f} minutes.\")\n",
    "        return\n",
    "\n",
    "    # --- Merge Each Set of Debuffered TMRT Tiles using GDAL ---\n",
    "    for tmrt_type, file_list_to_merge in organized_debuffered_files.items():\n",
    "        if not file_list_to_merge:\n",
    "            print(f\"No files to merge for TMRT type: {tmrt_type}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nAttempting to merge {len(file_list_to_merge)} debuffered tiles for TMRT type: {tmrt_type}...\")\n",
    "        merged_tmrt_output_path = os.path.join(merged_output_dir, f\"{tmrt_type}_merged_final.tif\")\n",
    "        vrt_path = os.path.join(merged_output_dir, f\"{tmrt_type}_temp.vrt\") # Temporary VRT\n",
    "\n",
    "        try:\n",
    "            # 1. Build VRT\n",
    "            # Ensure file_list_to_merge contains valid paths\n",
    "            valid_files_for_vrt = [f for f in file_list_to_merge if os.path.exists(f)]\n",
    "            if not valid_files_for_vrt:\n",
    "                print(f\"ERROR: No valid source files found for merging {tmrt_type} after checking existence.\")\n",
    "                continue\n",
    "            \n",
    "            vrt_options = gdal.BuildVRTOptions(resampleAlg='nearest', addAlpha=False) # Adjust options as needed\n",
    "            vrt_ds = gdal.BuildVRT(vrt_path, valid_files_for_vrt, options=vrt_options)\n",
    "            if vrt_ds is None:\n",
    "                print(f\"ERROR: Failed to build VRT for {tmrt_type}.\")\n",
    "                continue\n",
    "            vrt_ds = None # Close VRT dataset\n",
    "\n",
    "            # 2. Translate VRT to final TIFF\n",
    "            nodata_val = None\n",
    "            if valid_files_for_vrt:\n",
    "                first_tile_ds = gdal.Open(valid_files_for_vrt[0])\n",
    "                if first_tile_ds:\n",
    "                    nodata_val = first_tile_ds.GetRasterBand(1).GetNoDataValue()\n",
    "                    first_tile_ds = None # Close it\n",
    "\n",
    "            translate_options_list = [\"COMPRESS=LZW\", \"TILED=YES\", \"BIGTIFF=IF_SAFER\"]\n",
    "            if nodata_val is not None:\n",
    "                # gdal.Translate expects NoData as a string if it's part of creationOptions,\n",
    "                # or use the noData parameter directly.\n",
    "                # For gdal.Translate, the parameter is `noData`\n",
    "                final_ds = gdal.Translate(merged_tmrt_output_path, vrt_path,\n",
    "                                          format=\"GTiff\",\n",
    "                                          creationOptions=translate_options_list,\n",
    "                                          noData=nodata_val if nodata_val is not None else 'none') # Use 'none' if no nodata\n",
    "            else:\n",
    "                 final_ds = gdal.Translate(merged_tmrt_output_path, vrt_path,\n",
    "                                          format=\"GTiff\",\n",
    "                                          creationOptions=translate_options_list)\n",
    "\n",
    "\n",
    "            if final_ds is None:\n",
    "                print(f\"ERROR: Failed to translate VRT to TIFF for {tmrt_type}.\")\n",
    "                if os.path.exists(vrt_path): os.remove(vrt_path) # Clean up VRT\n",
    "                continue\n",
    "            final_ds = None # Close final dataset\n",
    "\n",
    "            print(f\"Successfully merged {tmrt_type} tiles to: {merged_tmrt_output_path}\")\n",
    "            if os.path.exists(vrt_path):\n",
    "                os.remove(vrt_path) # Clean up VRT\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during GDAL merging of {tmrt_type} tiles: {e}\\n{traceback.format_exc()}\")\n",
    "            if os.path.exists(vrt_path) and os.path.isfile(vrt_path): # ensure it's a file before removing\n",
    "                 try:\n",
    "                     os.remove(vrt_path)\n",
    "                 except OSError as ose:\n",
    "                     print(f\"Could not remove temporary VRT {vrt_path}: {ose}\")\n",
    "\n",
    "\n",
    "    overall_proc_time = (time.time() - overall_start_time) / 60\n",
    "    print(f\"\\nTotal script execution time: {overall_proc_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Optional: Set multiprocessing start method if issues arise,\n",
    "    # but usually default ('fork' on Linux, 'spawn' on Win/macOS) is fine.\n",
    "    # try:\n",
    "    #     multiprocessing.set_start_method('spawn', force=True)\n",
    "    # except RuntimeError:\n",
    "    #     print(\"Could not set multiprocessing start method (might be already set or not allowed).\")\n",
    "    #     pass\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
