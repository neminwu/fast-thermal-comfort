{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "from qgis.core import QgsApplication\n",
    "app = QgsApplication([], False)\n",
    "app.setPrefixPath(\"/apps/anvil/external/apps/qgis/3.40.1-Bratislava\", True)\n",
    "# Use the actual plugin path\n",
    "plugin_path = os.path.expanduser(\"~/.local/share/QGIS/QGIS3/profiles/default/python/plugins\")\n",
    "app.setPluginPath(plugin_path)\n",
    "app.initQgis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if plugin_path not in sys.path:\n",
    "\tsys.path.append(plugin_path)\n",
    "\n",
    "import processing\n",
    "from processing.core.Processing import Processing\n",
    "\n",
    "try:\n",
    "    from processing_umep.processing_umep_provider import ProcessingUMEPProvider\n",
    "    umep_provider = ProcessingUMEPProvider()\n",
    "    QgsApplication.processingRegistry().addProvider(umep_provider)\n",
    "    print(\"UMEP imported\")\n",
    "except Exception as e:\n",
    "\tprint(\"UMEP import error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcf30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from osgeo import gdal, osr # osr is needed for SpatialReference\n",
    "import zipfile\n",
    "import time\n",
    "import traceback\n",
    "from qgis import processing # Assuming QGIS environment is correctly set up\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import shutil\n",
    "# === CONFIGURATION (Identical to your previous script) ===\n",
    "tile_size = 500\n",
    "buffer_pixels = 50\n",
    "\n",
    "# Temporary directories\n",
    "base_source_data_dir = \"/storage/scratch1/4/hyu483/no_heat/UTCI/Input/Final_Run\"\n",
    "temp_base_dir = \"/storage/scratch1/4/hyu483/no_heat/UTCI/Temp/Final_Run_208_1300D\"\n",
    "base_tile_buffered_input_dir = os.path.join(temp_base_dir, \"Buffered_Inputs\")\n",
    "base_utci_buffered_output_dir = os.path.join(temp_base_dir, \"Buffered_UTCI_Output\")\n",
    "\n",
    "PATHS_CONFIG = {\n",
    "    \"TMRT\": \"/storage/home/hcoda1/4/hyu483/scratch/no_heat/SOLWEIG/Output/Final_Run_2/Interpolated_Output_Scipy/Tmrt_2023_208_1300D.tif\",\n",
    "    \"UROCK\": os.path.join(base_source_data_dir, \"merged_urock_final_filled_scipy.tif\"),\n",
    "    \"BUILDING\": os.path.join(base_source_data_dir, \"buildings.tif\"),\n",
    "    \"MET\": os.path.join(base_source_data_dir, \"metforcing.txt\")\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "final_output_base_dir = \"/storage/scratch1/4/hyu483/no_heat/UTCI/Output/Final_Run_208_1300D\"\n",
    "base_tile_debuffered_output_dir = os.path.join(final_output_base_dir, \"Debuffered_Tiles\")\n",
    "merged_output_dir = os.path.join(final_output_base_dir, \"Merged_Output\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82908ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.UseExceptions() # Enable GDAL exceptions\n",
    "\n",
    "# === HELPER FUNCTION ===\n",
    "def calculate_gdal_sub_geotransform(parent_gt, x_offset_pixels, y_offset_pixels):\n",
    "    \"\"\"\n",
    "    Calculates the GeoTransform for a sub-window of a raster based on pixel offsets.\n",
    "    \"\"\"\n",
    "    # parent_gt = [ulx, x_res, x_skew, uly, y_skew, y_res]\n",
    "    new_ulx = parent_gt[0] + x_offset_pixels * parent_gt[1] + y_offset_pixels * parent_gt[2]\n",
    "    new_uly = parent_gt[3] + x_offset_pixels * parent_gt[4] + y_offset_pixels * parent_gt[5]\n",
    "    return (new_ulx, parent_gt[1], parent_gt[2], new_uly, parent_gt[4], parent_gt[5])\n",
    "\n",
    "\n",
    "def gdal_slice_raster_by_window(\n",
    "    raster_path: str,\n",
    "    out_path: str,\n",
    "    slice_c_off: int,  # Column offset (x-pixel offset)\n",
    "    slice_r_off: int,  # Row offset (y-pixel offset)\n",
    "    slice_win_width: int, # Width of the window in pixels\n",
    "    slice_win_height: int, # Height of the window in pixels\n",
    "    output_format: str = \"GTiff\",\n",
    "    resample_alg: str = \"nearest\", # Resampling algorithm (e.g., 'nearest', 'bilinear').\n",
    "                                    # Note: For simple cropping with srcWin, this primarily affects\n",
    "                                    # output if width/height/resolution parameters are also used to\n",
    "                                    # change the output dimensions from the source window size.\n",
    "    creation_options: list = None # List of creation options for the output format (e.g., [\"TILED=YES\", \"COMPRESS=LZW\"])\n",
    "):\n",
    "    \"\"\"\n",
    "    Slices a raster image by a pixel window using GDAL's gdal.Translate function.\n",
    "\n",
    "    Args:\n",
    "        raster_path (str): Path to the input raster file.\n",
    "        out_path (str): Path for the output sliced raster file.\n",
    "        slice_c_off (int): Column offset (x-pixel offset) for the top-left corner of the window.\n",
    "        slice_r_off (int): Row offset (y-pixel offset) for the top-left corner of the window.\n",
    "        slice_win_width (int): Width of the window in pixels.\n",
    "        slice_win_height (int): Height of the window in pixels.\n",
    "        output_format (str, optional): Output raster format (e.g., \"GTiff\"). Defaults to \"GTiff\".\n",
    "        resample_alg (str, optional): Resampling algorithm. Defaults to \"bilinear\".\n",
    "        creation_options (list, optional): List of creation options for the output driver.\n",
    "                                          Defaults to [\"TILED=YES\", \"COMPRESS=LZW\"].\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the created output raster file.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If GDAL fails to open the input raster or fails during translation.\n",
    "    \"\"\"\n",
    "    if creation_options is None:\n",
    "        creation_options = [\"TILED=YES\", \"COMPRESS=LZW\"]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    out_dir = os.path.dirname(out_path)\n",
    "    if out_dir and not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Build the TranslateOptions.\n",
    "    # srcWin parameter is used to specify the window of pixels to extract.\n",
    "    # It takes a list/tuple: [xoff, yoff, xsize, ysize]\n",
    "    translate_opts = gdal.TranslateOptions(\n",
    "        format=output_format,\n",
    "        srcWin=[slice_c_off, slice_r_off, slice_win_width, slice_win_height],\n",
    "        resampleAlg=resample_alg,\n",
    "        creationOptions=creation_options\n",
    "    )\n",
    "\n",
    "    # Perform the translation (cropping)\n",
    "    # gdal.Translate returns a Dataset object on success, or None on failure.\n",
    "    ds = gdal.Translate(\n",
    "        destName=out_path,  # Path for the output raster\n",
    "        srcDS=raster_path,  # Path to the input raster\n",
    "        options=translate_opts # Translation options\n",
    "    )\n",
    "\n",
    "    # Check if the translation was successful\n",
    "    if ds is None:\n",
    "        raise RuntimeError(\"gdal.Translate failed to slice the raster.\")\n",
    "\n",
    "    # Close the dataset explicitly to ensure data is written to disk and resources are released.\n",
    "    ds = None\n",
    "\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# === FUNCTION TO DEBUFFER AND SAVE RASTER (GDAL) ===\n",
    "def debuffer_and_save_raster_gdal(\n",
    "    buffered_raster_path: str,\n",
    "    debuffered_raster_path: str,\n",
    "    original_full_raster_geotransform: tuple, # GeoTransform of the *original* large source raster\n",
    "    original_core_tile_col_off_in_full: int, # Column offset of the core tile within the full raster\n",
    "    original_core_tile_row_off_in_full: int, # Row offset of the core tile within the full raster\n",
    "    core_tile_width: int,                   # Width of the non-buffered core data\n",
    "    core_tile_height: int,                  # Height of the non-buffered core data\n",
    "    actual_buffer_on_left_pixels: int,      # Buffer pixels on the left *within the buffered_raster_path*\n",
    "    actual_buffer_on_top_pixels: int        # Buffer pixels on the top *within the buffered_raster_path*\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Clips the core data from a buffered raster using GDAL and saves it\n",
    "    with correct global georeferencing.\n",
    "    \"\"\"\n",
    "    src_buffered_ds = gdal.Open(buffered_raster_path, gdal.GA_ReadOnly)\n",
    "    if src_buffered_ds is None:\n",
    "        print(f\"ERROR: Could not open buffered raster: {buffered_raster_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        src_buffered_band = src_buffered_ds.GetRasterBand(1)\n",
    "        if src_buffered_band is None:\n",
    "            print(f\"ERROR: Could not get band from {buffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "        # Read the core data from the buffered raster\n",
    "        # xoff, yoff, xsize, ysize for ReadAsArray\n",
    "        core_data = src_buffered_band.ReadAsArray(\n",
    "            xoff=actual_buffer_on_left_pixels,\n",
    "            yoff=actual_buffer_on_top_pixels,\n",
    "            win_xsize=core_tile_width,\n",
    "            win_ysize=core_tile_height\n",
    "        ).astype(float)\n",
    "\n",
    "        if core_data is None:\n",
    "            print(f\"ERROR: Failed to read core data from {buffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "        \n",
    "        if core_data.shape[0] != core_tile_height or core_data.shape[1] != core_tile_width:\n",
    "            print(f\"ERROR: Read core data shape ({core_data.shape}) does not match expected ({core_tile_height}, {core_tile_width}) for {debuffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "\n",
    "        # Calculate the correct geotransform for this debuffered (core) tile.\n",
    "        # This transform places the core tile in its correct global position.\n",
    "        final_core_geotransform = calculate_gdal_sub_geotransform(\n",
    "            original_full_raster_geotransform,\n",
    "            original_core_tile_col_off_in_full,\n",
    "            original_core_tile_row_off_in_full\n",
    "        )\n",
    "\n",
    "        # Create the output debuffered raster\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        if driver is None:\n",
    "            print(\"ERROR: GTiff driver not available.\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "            \n",
    "        os.makedirs(os.path.dirname(debuffered_raster_path), exist_ok=True)\n",
    "        \n",
    "        # Get data type from source buffered band\n",
    "        gdal_data_type = src_buffered_band.DataType\n",
    "        \n",
    "        dst_ds = driver.Create(\n",
    "            debuffered_raster_path,\n",
    "            xsize=core_tile_width,\n",
    "            ysize=core_tile_height,\n",
    "            bands=1, # Assuming single band TMRT\n",
    "            eType=gdal_data_type,\n",
    "            options=[\"COMPRESS=LZW\"] # Add other options if needed\n",
    "        )\n",
    "        if dst_ds is None:\n",
    "            print(f\"ERROR: Could not create output raster: {debuffered_raster_path}\")\n",
    "            src_buffered_ds = None\n",
    "            return None\n",
    "\n",
    "        dst_ds.SetGeoTransform(final_core_geotransform)\n",
    "        dst_ds.SetProjection(src_buffered_ds.GetProjection()) # Preserve CRS\n",
    "\n",
    "        dst_band = dst_ds.GetRasterBand(1)\n",
    "        dst_band.WriteArray(core_data)\n",
    "        no_data_value = src_buffered_band.GetNoDataValue()\n",
    "        if no_data_value is not None:\n",
    "            dst_band.SetNoDataValue(no_data_value)\n",
    "        \n",
    "        dst_band.FlushCache()\n",
    "        dst_ds = None # Close and save\n",
    "\n",
    "        return debuffered_raster_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during debuffering for {buffered_raster_path} to {debuffered_raster_path}: {e}\\n{traceback.format_exc()}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if src_buffered_ds:\n",
    "            src_buffered_ds = None\n",
    "\n",
    "\n",
    "# === WORKER FUNCTION FOR PROCESSING A SINGLE TILE ===\n",
    "def process_tile_with_buffer(\n",
    "    core_r_offset, core_c_offset,\n",
    "    core_tile_width, core_tile_height,\n",
    "    buffer_px,\n",
    "    full_raster_total_width, full_raster_total_height,\n",
    "    original_full_raster_geotransform_tuple, original_full_raster_crs_wkt, # GDAL specific\n",
    "    paths_cfg_dict,\n",
    "    base_buffered_input_dir_worker,\n",
    "    base_solweig_out_dir_worker,\n",
    "    base_debuffered_out_dir_worker,\n",
    "    tile_id_str\n",
    "    ):\n",
    "    print(f\"[{tile_id_str}] Starting processing with buffer...\")\n",
    "    tile_processing_start_time = time.time()\n",
    "    debuffered_output_files_for_this_tile = []\n",
    "\n",
    "    try:\n",
    "        # --- 1. Calculate Buffered Window for Slicing Inputs ---\n",
    "        slice_r_off = max(0, core_r_offset - buffer_px)\n",
    "        slice_c_off = max(0, core_c_offset - buffer_px)\n",
    "        slice_r_end = min(full_raster_total_height, core_r_offset + core_tile_height + buffer_px)\n",
    "        slice_c_end = min(full_raster_total_width, core_c_offset + core_tile_width + buffer_px)\n",
    "        slice_win_height = (slice_r_end - slice_r_off)\n",
    "        slice_win_width = (slice_c_end - slice_c_off)\n",
    "\n",
    "        if slice_win_width <= 0 or slice_win_height <= 0:\n",
    "            msg = f\"[{tile_id_str}] Skipped: Calculated buffered slice window has zero/negative dimension. W:{slice_win_width} H:{slice_win_height}\"\n",
    "            print(msg)\n",
    "            return msg # Return error/skip message\n",
    "\n",
    "        actual_buffer_left = core_c_offset - slice_c_off\n",
    "        actual_buffer_top = core_r_offset - slice_r_off\n",
    "\n",
    "        # --- 2. Prepare Directories for this Tile ---\n",
    "        current_tile_buffered_data_dir = os.path.join(base_buffered_input_dir_worker, tile_id_str)\n",
    "        current_tile_utci_output_dir = os.path.join(base_solweig_out_dir_worker, tile_id_str)\n",
    "        os.makedirs(current_tile_utci_output_dir, exist_ok=True)\n",
    "        current_tile_utci_output = os.path.join(current_tile_utci_output_dir, \"UTCI.tif\")\n",
    "        current_tile_debuffered_output_dir = os.path.join(base_debuffered_out_dir_worker, tile_id_str)\n",
    "        os.makedirs(current_tile_debuffered_output_dir, exist_ok=True)\n",
    "\n",
    "        # *** EDITED SECTION 1: CHECK FOR EXISTING OUTPUT ***\n",
    "        all_files_exist = os.path.exists(current_tile_utci_output)\n",
    "        if all_files_exist:\n",
    "            print(f\"[{tile_id_str}] Found all required UTCI output files. Skipping processing run.\")\n",
    "        else:\n",
    "            # --- 3. Slice Main Input Rasters (Buffered) ---\n",
    "            tile_specific_buffered_inputs = {}\n",
    "            for key in [\"TMRT\", \"UROCK\", \"BUILDING\"]:\n",
    "                in_path = paths_cfg_dict[key]\n",
    "                out_filename = os.path.basename(in_path)\n",
    "                out_path = os.path.join(current_tile_buffered_data_dir, out_filename)\n",
    "                tile_specific_buffered_inputs[key] = gdal_slice_raster_by_window(\n",
    "                    raster_path=in_path, out_path=out_path,\n",
    "                    slice_c_off=slice_c_off, slice_r_off=slice_r_off,\n",
    "                    slice_win_width=slice_win_width, slice_win_height=slice_win_height\n",
    "                )\n",
    "                if tile_specific_buffered_inputs[key] is None: # Check if slicing failed\n",
    "                     raise RuntimeError(f\"Failed to slice {key} for {tile_id_str}\")\n",
    "                    \n",
    "            for key in [\"MET\"]:\n",
    "                in_path = paths_cfg_dict[key]\n",
    "                out_filename = os.path.basename(in_path)\n",
    "                out_path = os.path.join(current_tile_buffered_data_dir, out_filename)\n",
    "                try:\n",
    "                    shutil.copy2(in_path, out_path) # copy2 preserves metadata\n",
    "                    tile_specific_buffered_inputs[key] = out_path\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"Failed to copy {key} for {tile_id_str}: {e}\")\n",
    "    \n",
    "            # --- 5. Run OUTDOOR THERMAL COMFORT SPATIAL THERMAL COMFORT on Buffered Inputs ---\n",
    "            processing.run(\"umep:Outdoor Thermal Comfort: Spatial Thermal Comfort\", \n",
    "               {'TMRT_MAP':tile_specific_buffered_inputs.get('TMRT'),\n",
    "                'UROCK_MAP':tile_specific_buffered_inputs.get('UROCK'),\n",
    "                'TC_TYPE':1,'AGE':35,'ACTIVITY':80,'CLO':0.9,'WEIGHT':75,\n",
    "                'HEIGHT':180,'SEX':0,'COMFA':False,'TC_OUT':current_tile_utci_output})\n",
    "    \n",
    "        # *** EDITED SECTION 2: CLEANUP ***\n",
    "        print(f\"[{tile_id_str}] Cleaning up temporary buffered input directory: {current_tile_buffered_data_dir}\")\n",
    "        try:\n",
    "            shutil.rmtree(current_tile_buffered_data_dir, ignore_errors=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[{tile_id_str}] WARNING: Could not clean up temporary directory {current_tile_buffered_data_dir}: {e}\")\n",
    "\n",
    "        proc_time = (time.time() - tile_processing_start_time) / 60\n",
    "        print(f\"[{tile_id_str}] Tile task finished in {proc_time:.2f} mins.\")\n",
    "        \n",
    "        # --- 6. Debuffer the Output ---\n",
    "        utci_glob_pattern = os.path.join(current_tile_utci_output_dir, \"UTCI.tif\")\n",
    "        all_buffered_utci_files = glob.glob(utci_glob_pattern)\n",
    "\n",
    "        if not all_buffered_utci_files:\n",
    "            print(f\"[{tile_id_str}] WARNING: No TMRT output files found in {current_tile_utci_output_dir} after SOLWEIG run.\")\n",
    "            # This might not be an error if SOLWEIG was not expected to produce TMRT in some cases\n",
    "            # but usually it's an indication of a problem with the SOLWEIG run itself.\n",
    "        \n",
    "        for buffered_utci_path in all_buffered_utci_files:\n",
    "            buffered_utci_filename_base = os.path.basename(buffered_utci_path)\n",
    "            debuffered_utci_filename = f\"{os.path.splitext(buffered_utci_filename_base)[0]}_{tile_id_str}_debuffered.tif\"\n",
    "            debuffered_utci_path = os.path.join(current_tile_debuffered_output_dir, debuffered_utci_filename)\n",
    "\n",
    "            if os.path.exists(debuffered_utci_path):\n",
    "                debuffered_output_files_for_this_tile.append(debuffered_utci_path)\n",
    "                print(f\"[{tile_id_str}] already exists: {debuffered_utci_path}\")\n",
    "            else:\n",
    "                # Parameters for debuffer_and_save_raster_gdal:\n",
    "                debuffered_file = debuffer_and_save_raster_gdal(\n",
    "                    buffered_raster_path=buffered_utci_path,\n",
    "                    debuffered_raster_path=debuffered_utci_path,\n",
    "                    original_full_raster_geotransform=original_full_raster_geotransform_tuple,\n",
    "                    original_core_tile_col_off_in_full=core_c_offset,\n",
    "                    original_core_tile_row_off_in_full=core_r_offset,\n",
    "                    core_tile_width=core_tile_width,\n",
    "                    core_tile_height=core_tile_height,\n",
    "                    actual_buffer_on_left_pixels=actual_buffer_left,\n",
    "                    actual_buffer_on_top_pixels=actual_buffer_top\n",
    "                )\n",
    "                if debuffered_file:\n",
    "                    debuffered_output_files_for_this_tile.append(debuffered_file)\n",
    "                    print(f\"[{tile_id_str}] Successfully debuffered: {debuffered_file}\")\n",
    "                else:\n",
    "                    print(f\"[{tile_id_str}] ERROR failed to debuffer: {buffered_tmrt_path}\")\n",
    "\n",
    "        if not debuffered_output_files_for_this_tile and all_buffered_utci_files:\n",
    "            msg = f\"[{tile_id_str}] ERROR: Found TMRT files but failed to debuffer any.\"\n",
    "            print(msg)\n",
    "            return msg\n",
    "        \n",
    "        proc_time = (time.time() - tile_processing_start_time) / 60\n",
    "        msg = f\"[{tile_id_str}] Tile processing (buffered) complete in {proc_time:.2f} mins. {len(debuffered_output_files_for_this_tile)} TMRT files debuffered.\"\n",
    "        print(msg)\n",
    "        return debuffered_output_files_for_this_tile\n",
    "\n",
    "    except Exception as e:\n",
    "        err_msg = f\"[{tile_id_str}] ERROR processing tile: {e}\\n{traceback.format_exc()}\"\n",
    "        print(err_msg)\n",
    "        return err_msg\n",
    "\n",
    "\n",
    "# === MAIN SCRIPT EXECUTION ===\n",
    "def main():\n",
    "    overall_start_time = time.time()\n",
    "    os.makedirs(base_tile_buffered_input_dir, exist_ok=True)\n",
    "    os.makedirs(base_utci_buffered_output_dir, exist_ok=True)\n",
    "    os.makedirs(base_tile_debuffered_output_dir, exist_ok=True)\n",
    "    os.makedirs(merged_output_dir, exist_ok=True)\n",
    "\n",
    "    # --- Get dimensions and georeferencing from one of the main full-sized rasters using GDAL ---\n",
    "    ref_ds = gdal.Open(PATHS_CONFIG['TMRT'], gdal.GA_ReadOnly)\n",
    "    if ref_ds is None:\n",
    "        print(f\"CRITICAL ERROR: Could not open reference raster: {PATHS_CONFIG['TMRT']}\")\n",
    "        return\n",
    "    full_raster_width = ref_ds.RasterXSize\n",
    "    full_raster_height = ref_ds.RasterYSize\n",
    "    original_raster_geotransform = ref_ds.GetGeoTransform() # Tuple\n",
    "    original_raster_crs_wkt = ref_ds.GetProjection()     # WKT string\n",
    "    ref_ds = None # Close it\n",
    "    print(f\"Full source raster dimensions: {full_raster_width}x{full_raster_height}, Tile Size: {tile_size}x{tile_size}, Buffer: {buffer_pixels}px\")\n",
    "    print(f\"Source GeoTransform: {original_raster_geotransform}\")\n",
    "    print(f\"Source CRS (WKT): {original_raster_crs_wkt[:100]}...\") # Print first 100 chars\n",
    "\n",
    "    tasks_for_pool = []\n",
    "\n",
    "    for r_idx, core_r_off in enumerate(range(0, full_raster_height, tile_size)):\n",
    "        for c_idx, core_c_off in enumerate(range(0, full_raster_height, tile_size)):\n",
    "            current_core_tile_width = min(tile_size, full_raster_width - core_c_off)\n",
    "            current_core_tile_height = min(tile_size, full_raster_height - core_r_off)\n",
    "\n",
    "            if current_core_tile_width <= 0 or current_core_tile_height <= 0:\n",
    "                print(f\"Skipping task generation for zero-dimension core tile at r_offset={core_r_off}, c_offset={core_c_off}\")\n",
    "                continue\n",
    "            \n",
    "            tile_identifier_string = f\"tile_{r_idx}_{c_idx}\"\n",
    "            task_args = (\n",
    "                core_r_off, core_c_off,\n",
    "                current_core_tile_width, current_core_tile_height,\n",
    "                buffer_pixels,\n",
    "                full_raster_width, full_raster_height,\n",
    "                original_raster_geotransform, original_raster_crs_wkt, # Pass GDAL specific info\n",
    "                PATHS_CONFIG,\n",
    "                base_tile_buffered_input_dir,\n",
    "                base_utci_buffered_output_dir,\n",
    "                base_tile_debuffered_output_dir,\n",
    "                tile_identifier_string\n",
    "            )\n",
    "            tasks_for_pool.append(task_args)\n",
    "\n",
    "    if not tasks_for_pool:\n",
    "        print(\"No tasks generated.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nGenerated {len(tasks_for_pool)} tasks for multiprocessing.\")\n",
    "    num_processes = min(max(1, os.cpu_count() - 2), 40)\n",
    "    # num_processes = 1 # For testing\n",
    "    print(f\"Using {num_processes} processes.\")\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results_from_pool = pool.starmap(process_tile_with_buffer, tasks_for_pool)\n",
    "    \n",
    "    print(\"\\n=== Multiprocessing of tiles complete. ===\")\n",
    "\n",
    "    organized_debuffered_files = {}\n",
    "    failed_tile_processing_count = 0\n",
    "    for result_item in results_from_pool:\n",
    "        if isinstance(result_item, str) and (\"ERROR\" in result_item or \"Skipped\" in result_item or \"WARNING\" in result_item): # Check for string error messages\n",
    "            failed_tile_processing_count += 1\n",
    "            # Error/skip message already printed by worker\n",
    "        elif isinstance(result_item, list): # Successful result is a list of debuffered paths\n",
    "            for debuffered_path in result_item:\n",
    "                if os.path.exists(debuffered_path):\n",
    "                    filename = os.path.basename(debuffered_path)\n",
    "                    parts = filename.split('_tile_')[0]\n",
    "                    tmrt_type_key = parts\n",
    "                    if tmrt_type_key not in organized_debuffered_files:\n",
    "                        organized_debuffered_files[tmrt_type_key] = []\n",
    "                    organized_debuffered_files[tmrt_type_key].append(debuffered_path)\n",
    "                else:\n",
    "                    print(f\"Warning: Worker reported debuffered file, but not found: {debuffered_path}\")\n",
    "        else: # Unrecognized result type\n",
    "            failed_tile_processing_count +=1\n",
    "            print(f\"  Unknown result type from worker for a tile: {type(result_item)} - {str(result_item)[:200]}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nTile processing summary: {len(results_from_pool) - failed_tile_processing_count} tiles had successful outcomes (returned list of paths).\")\n",
    "    print(f\"Tiles that returned error/skip messages or unknown result types: {failed_tile_processing_count}\")\n",
    "\n",
    "\n",
    "    if not organized_debuffered_files:\n",
    "        print(\"No debuffered files were successfully organized for merging.\")\n",
    "        overall_proc_time_early_exit = (time.time() - overall_start_time) / 60\n",
    "        print(f\"\\nTotal script execution time: {overall_proc_time_early_exit:.2f} minutes.\")\n",
    "        return\n",
    "\n",
    "    # --- Merge Each Set of Debuffered TMRT Tiles using GDAL ---\n",
    "    for tmrt_type, file_list_to_merge in organized_debuffered_files.items():\n",
    "        if not file_list_to_merge:\n",
    "            print(f\"No files to merge for TMRT type: {tmrt_type}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nAttempting to merge {len(file_list_to_merge)} debuffered tiles for TMRT type: {tmrt_type}...\")\n",
    "        merged_tmrt_output_path = os.path.join(merged_output_dir, f\"{tmrt_type}_merged_final.tif\")\n",
    "        vrt_path = os.path.join(merged_output_dir, f\"{tmrt_type}_temp.vrt\") # Temporary VRT\n",
    "\n",
    "        try:\n",
    "            # 1. Build VRT\n",
    "            # Ensure file_list_to_merge contains valid paths\n",
    "            valid_files_for_vrt = [f for f in file_list_to_merge if os.path.exists(f)]\n",
    "            if not valid_files_for_vrt:\n",
    "                print(f\"ERROR: No valid source files found for merging {tmrt_type} after checking existence.\")\n",
    "                continue\n",
    "            \n",
    "            vrt_options = gdal.BuildVRTOptions(resampleAlg='nearest', addAlpha=False) # Adjust options as needed\n",
    "            vrt_ds = gdal.BuildVRT(vrt_path, valid_files_for_vrt, options=vrt_options)\n",
    "            if vrt_ds is None:\n",
    "                print(f\"ERROR: Failed to build VRT for {tmrt_type}.\")\n",
    "                continue\n",
    "            vrt_ds = None # Close VRT dataset\n",
    "\n",
    "            # 2. Translate VRT to final TIFF\n",
    "            nodata_val = None\n",
    "            if valid_files_for_vrt:\n",
    "                first_tile_ds = gdal.Open(valid_files_for_vrt[0])\n",
    "                if first_tile_ds:\n",
    "                    nodata_val = first_tile_ds.GetRasterBand(1).GetNoDataValue()\n",
    "                    first_tile_ds = None # Close it\n",
    "\n",
    "            translate_options_list = [\"COMPRESS=LZW\", \"TILED=YES\", \"BIGTIFF=IF_SAFER\"]\n",
    "            if nodata_val is not None:\n",
    "                # gdal.Translate expects NoData as a string if it's part of creationOptions,\n",
    "                # or use the noData parameter directly.\n",
    "                # For gdal.Translate, the parameter is `noData`\n",
    "                final_ds = gdal.Translate(merged_tmrt_output_path, vrt_path,\n",
    "                                          format=\"GTiff\",\n",
    "                                          creationOptions=translate_options_list,\n",
    "                                          noData=nodata_val if nodata_val is not None else 'none') # Use 'none' if no nodata\n",
    "            else:\n",
    "                 final_ds = gdal.Translate(merged_tmrt_output_path, vrt_path,\n",
    "                                          format=\"GTiff\",\n",
    "                                          creationOptions=translate_options_list)\n",
    "\n",
    "\n",
    "            if final_ds is None:\n",
    "                print(f\"ERROR: Failed to translate VRT to TIFF for {tmrt_type}.\")\n",
    "                if os.path.exists(vrt_path): os.remove(vrt_path) # Clean up VRT\n",
    "                continue\n",
    "            final_ds = None # Close final dataset\n",
    "\n",
    "            print(f\"Successfully merged {tmrt_type} tiles to: {merged_tmrt_output_path}\")\n",
    "            if os.path.exists(vrt_path):\n",
    "                os.remove(vrt_path) # Clean up VRT\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during GDAL merging of {tmrt_type} tiles: {e}\\n{traceback.format_exc()}\")\n",
    "            if os.path.exists(vrt_path) and os.path.isfile(vrt_path): # ensure it's a file before removing\n",
    "                 try:\n",
    "                     os.remove(vrt_path)\n",
    "                 except OSError as ose:\n",
    "                     print(f\"Could not remove temporary VRT {vrt_path}: {ose}\")\n",
    "\n",
    "\n",
    "    overall_proc_time = (time.time() - overall_start_time) / 60\n",
    "    print(f\"\\nTotal script execution time: {overall_proc_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
