{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87fabdd",
   "metadata": {},
   "source": [
    "# 1. Download LiDAR and DEM data from USGS\n",
    "\n",
    "This function is to download DEM and LiDAR at the same time tiles that Atlanta's City Boundary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "### --- Configuration (User MUST update these paths) --- ###\n",
    "TIFF_URL_LIST_FILE = r\"C:\\Users\\HojungYu\\Documents\\GitHub\\fast-thermal-comfort\\data\\0_file_download_links.txt\" # This will be downloaded text file.\n",
    "DOWNLOAD_DIR_DEM = r\"C:\\Users\\HojungYu\\Documents\\GitHub\\fast-thermal-comfort\\data\\DEM\" # DEM directory\n",
    "DOWNLOAD_DIR_LIDAR = r\"C:\\Users\\HojungYu\\Documents\\GitHub\\fast-thermal-comfort\\data\\LiDAR\" # LiDAR directory \n",
    "ATLANTA_BOUNDARY_FILE = r\"C:\\Users\\HojungYu\\Documents\\GitHub\\fast-thermal-comfort\\data\\Atlanta_City_buffered.geojson\" # Atlanta Boundary geojson. Used buffered version to make sure you have all tiles inside.\n",
    "### ---------------------------------------------------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74930ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "def load_atlanta_boundary(boundary_filepath):\n",
    "    \"\"\"\n",
    "    Loads Atlanta's city boundary using geopandas.\n",
    "    Args:\n",
    "        boundary_filepath (str): Path to the geospatial file for Atlanta's boundary.\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame containing Atlanta's boundary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        atlanta_gdf = gpd.read_file(boundary_filepath)\n",
    "        if atlanta_gdf.crs is None or atlanta_gdf.crs.to_epsg() != 4326:\n",
    "            print(f\"Warning: Atlanta boundary CRS is {atlanta_gdf.crs}. Reprojecting to EPSG:4326.\")\n",
    "            atlanta_gdf = atlanta_gdf.to_crs(epsg=4326)\n",
    "        print(f\"Successfully loaded Atlanta boundary from: {boundary_filepath}\")\n",
    "        return atlanta_gdf\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load Atlanta boundary from '{boundary_filepath}': {e}\")\n",
    "        print(\"Using a simplified placeholder bounding box for Atlanta. Please provide a real file for accuracy.\")\n",
    "        west = -84.50\n",
    "        south = 33.65\n",
    "        east = -84.30\n",
    "        north = 33.85\n",
    "        atlanta_bbox_polygon = Polygon([(west, south), (east, south), (east, north), (west, north), (west, south)])\n",
    "        return gpd.GeoDataFrame(\n",
    "            {'geometry': [atlanta_bbox_polygon]},\n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "\n",
    "def extract_id_from_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the ID (e.g., 'e0999n1337') from a TIFF URL.\n",
    "    \"\"\"\n",
    "    match = re.search(r'_(e\\d+n\\d+)\\.tif$', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def construct_xml_url(tif_url, tif_id):\n",
    "    \"\"\"\n",
    "    Constructs the XML metadata URL from a TIFF URL and its ID.\n",
    "    Assumes a consistent URL structure for metadata.\n",
    "    \"\"\"\n",
    "    # Example TIFF URL: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/OPR/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B2_2018/TIFF/USGS_OPR_GA_Statewide_2018_B18_DRRA_e0999n1337.tif\n",
    "    # Example XML URL: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/OPR/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B2_2018/metadata/USGS_OPR_GA_Statewide_2018_B18_DRRA_e1089n1369.xml\n",
    "    # Note the 'B2_2018' vs 'B3_2018' and 'TIFF' vs 'metadata'\n",
    "    base_url = tif_url.rsplit('/', 2)[0] # Get base up to 'GA_Statewide_B2_2018'\n",
    "    xml_url = f\"{base_url}/metadata/USGS_OPR_GA_Statewide_2018_B18_DRRA_{tif_id}.xml\"\n",
    "    return xml_url\n",
    "\n",
    "def construct_laz_url(tif_url, tif_id):\n",
    "    \"\"\"\n",
    "    Constructs the LAZ download URL from an ID.\n",
    "    Assumes a consistent URL structure for LAZ files.\n",
    "    Example TIF URL: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/OPR/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B2_2018/TIFF/USGS_OPR_GA_Statewide_2018_B18_DRRA_{ID}.tif\n",
    "    Example LAZ URL: https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B2_2018/LAZ/USGS_LPC_GA_Statewide_2018_B18_DRRA_{ID}.laz\n",
    "    \"\"\"\n",
    "    # This URL structure is different from the TIFF/XML, so it's hardcoded based on the example.\n",
    "    laz_base_url = tif_url.split('/')[7:9]\n",
    "    laz_base_url_str = \"/\".join(laz_base_url) \n",
    "    laz_base_url_2 = tif_url.rsplit('/', 1)[1]\n",
    "    laz_base_url_2=laz_base_url_2.replace(\"USGS_OPR_GA\", \"USGS_LPC_GA\")\n",
    "    laz_base_url_2=laz_base_url_2.replace(\"tif\",\"laz\")\n",
    "    laz_url = f\"https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/{laz_base_url_str}/LAZ/{laz_base_url_2}\"\n",
    "    return laz_url\n",
    "\n",
    "def download_file(url, destination_folder):\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL to a specified folder.\n",
    "    Returns the path to the downloaded file, or None on failure.\n",
    "    \"\"\"\n",
    "    # os.makedirs(destination_folder, exist_ok=True)\n",
    "    local_filename = os.path.join(destination_folder, url.split('/')[-1])\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        # print(f\"Downloaded: {local_filename}\")\n",
    "        return local_filename\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_xml_bounding_box(xml_filepath):\n",
    "    \"\"\"\n",
    "    Parses an XML file to extract bounding box coordinates.\n",
    "    Returns a shapely Polygon representing the bounding box, or None if not found/parsed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_filepath)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Define the namespace if present, or search without it\n",
    "\n",
    "        def find_element_text(parent, tag_name):\n",
    "            # Search for element with or without namespace\n",
    "            element = parent.find(tag_name)\n",
    "            if element is None:\n",
    "                # Try with common namespaces\n",
    "                for ns_prefix in ['', '{http://www.fgdc.gov/metadata/fgdc-std-001-1998.xsd}', '{http://www.isotc211.org/2005/gmd}']:\n",
    "                    element = parent.find(f'{ns_prefix}{tag_name}')\n",
    "                    if element is not None:\n",
    "                        break\n",
    "            return element.text if element is not None else None\n",
    "\n",
    "        # Find the bounding box elements\n",
    "        westbc = find_element_text(root.find('.//bounding'), 'westbc')\n",
    "        eastbc = find_element_text(root.find('.//bounding'), 'eastbc')\n",
    "        northbc = find_element_text(root.find('.//bounding'), 'northbc')\n",
    "        southbc = find_element_text(root.find('.//bounding'), 'southbc')\n",
    "\n",
    "        if all([westbc, eastbc, northbc, southbc]):\n",
    "            west = float(westbc)\n",
    "            east = float(eastbc)\n",
    "            north = float(northbc)\n",
    "            south = float(southbc)\n",
    "            bbox_polygon = Polygon([(west, south), (east, south), (east, north), (west, north), (west, south)])\n",
    "            return bbox_polygon\n",
    "        else:\n",
    "            print(f\"Warning: Could not find all bounding box coordinates in {xml_filepath}\")\n",
    "            return None\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML file {xml_filepath}: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting bounding box coordinates to float in {xml_filepath}: {e}\")\n",
    "        return None\n",
    "    except AttributeError: # Happens if .//bounding is not found\n",
    "        print(f\"Warning: 'bounding' element not found in XML file {xml_filepath}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1. Load Atlanta's boundary\n",
    "    atlanta_boundary_gdf = load_atlanta_boundary(ATLANTA_BOUNDARY_FILE)\n",
    "    if atlanta_boundary_gdf is None or atlanta_boundary_gdf.empty:\n",
    "        print(\"Failed to load or create Atlanta boundary. Exiting.\")\n",
    "        return\n",
    "\n",
    "    atlanta_union_geometry = atlanta_boundary_gdf.geometry.unary_union\n",
    "\n",
    "    os.makedirs(DOWNLOAD_DIR_DEM, exist_ok=True)\n",
    "    os.makedirs(DOWNLOAD_DIR_LIDAR, exist_ok=True)\n",
    "    \n",
    "    # 2. Process the list of URLs\n",
    "    try:\n",
    "        with open(TIFF_URL_LIST_FILE, 'r') as f:\n",
    "            tiff_urls = [line.strip() for line in f if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: TIFF URL list file not found at {TIFF_URL_LIST_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nProcessing {len(tiff_urls)} TIFF URLs...\")\n",
    "\n",
    "    for i, tif_url in enumerate(tiff_urls):\n",
    "        tif_id = extract_id_from_url(tif_url)\n",
    "        if not tif_id:\n",
    "            print(f\"Skipping: Could not extract ID from {tif_url}\")\n",
    "            continue\n",
    "        xml_url = construct_xml_url(tif_url, tif_id)\n",
    "        if not xml_url:\n",
    "            print(f\"Skipping: Could not construct XML URL for {tif_id}\")\n",
    "            continue\n",
    "\n",
    "        xml_filepath = download_file(xml_url, DOWNLOAD_DIR_LIDAR)\n",
    "        if not xml_filepath:\n",
    "            print(f\"Skipping: Failed to download XML for {tif_id}\")\n",
    "            continue\n",
    "        data_bbox_polygon = parse_xml_bounding_box(xml_filepath)\n",
    "        try:\n",
    "            os.remove(xml_filepath)\n",
    "            # print(f\"Removed temporary XML file: {xml_filepath}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error removing temporary XML file {xml_filepath}: {e}\")\n",
    "        if data_bbox_polygon:\n",
    "            data_bbox_geoseries = gpd.GeoSeries([data_bbox_polygon], crs=\"EPSG:4326\")\n",
    "            if data_bbox_geoseries.intersects(atlanta_union_geometry).any():\n",
    "                # print(f\"Bounding box for ID {tif_id} intersects with Atlanta's boundary.\")\n",
    "\n",
    "                # 3. Download TIFF and LAZ files\n",
    "                laz_url = construct_laz_url(tif_url, tif_id)\n",
    "\n",
    "                print(f\"Initiating download for TIFF: {tif_url}\")\n",
    "                download_file(tif_url, DOWNLOAD_DIR_DEM)\n",
    "\n",
    "                print(f\"Initiating download for LAZ: {laz_url}\")\n",
    "                download_file(laz_url, DOWNLOAD_DIR_LIDAR)\n",
    "            # else:\n",
    "                # print(f\"Bounding box for ID {tif_id} does NOT intersect with Atlanta's boundary. Skipping downloads.\")\n",
    "        else:\n",
    "            print(f\"Skipping: Could not get valid bounding box for ID {tif_id} from XML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81550ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Atlanta boundary from: C:\\Users\\HojungYu\\Documents\\GitHub\\fast-thermal-comfort\\data\\Atlanta_City_buffered.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HojungYu\\AppData\\Local\\Temp\\ipykernel_25256\\3766011893.py:8: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  atlanta_union_geometry = atlanta_boundary_gdf.geometry.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating download for TIFF: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/OPR/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B3_2018/TIFF/USGS_OPR_GA_Statewide_2018_B18_DRRA_e1072n1251.tif\n",
      "Initiating download for LAZ: https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/GA_Statewide_2018_B18_DRRA/GA_Statewide_B3_2018/LAZ/USGS_LPC_GA_Statewide_2018_B18_DRRA_e1072n1251.laz\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "no_heat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
